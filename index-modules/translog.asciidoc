[[index-modules-translog]]
== Translog

在Lucene中，更新操作只在commit时被持久化到磁盘中，这是一个相对较重的行为，并且每次索引或者删除
文档后就没法进行后续操作了。在两次commit中间的更新就可能在进程退出或者硬件错误时丢失。

为了防止这种数据丢失的情况发生， elasticsearch中给每个分片关联一个 _transaction log_
或者又叫预写式日志。每次索引或者删除操作都会在内部Lucene 索引处理完成后被写入到事务日志
中去。
当系统崩溃后，最近的事务会在分片恢复工作时从事务日志中被重放。

Elasticsearch中得每次flush操作就是执行Lucene的commit和开启一个新的事务日志。这是后台自动
进行的以避免事务日志变的太大，从而可以确保在恢复时重放操作的时间在可接受范围内。虽然也暴露了
API，但通常很少会需要手动触发flush操作。


[float]
=== Flush 设置

下面的 <<indices-update-settings,可动态设置>> 的配置决定了多久执行一次内存到磁盘的刷新操作。

`index.translog.flush_threshold_size`::

一旦事务日志大小达到这个数值，flush就会发生。默认为 `512mb`。

`index.translog.flush_threshold_ops`::

多少次操作后flush。默认为 `unlimited`。

`index.translog.flush_threshold_period`::

不管事务日志大小，多久执行一次flush操作。 默认为 `30m`。

`index.translog.interval`::

多久检查是否需要flush，实际取值为该值和2倍该值之间随机取一个。 该值默认为 `5s`。


[float]
=== 事务日志设置

事务日志中的数据只有在事务日志被++fsync++并提交后才会被持久化到磁盘上。如果发生硬件故障，事务日志
上次提交后的数据将会丢失。

默认情况下，Elasticsearch会每隔5秒执行 ++fsync++ 和commit操作，并且在每个
<<docs-index_,index>>, <<docs-delete,delete>>,
<<docs-update,update>>, 或者  <<docs-bulk,bulk>>请求执行完成后也会执行该操作。实际上，
Elasticsearch只会在事务日志被成功 ++fsync++ 并提交到主分片和每个分片副本上后才会向客户端
返回index, delete, update或者buld请求成功的响应。

`index.translog.sync_interval`::

多久执行一次 ++fsync++并提交，而不管是否有写入操作发生。 默认为 `5s`。

`index.translog.durability`::
+
--

是否每次index，delete，update或buld请求都需要执行 `fsync` 和commit操作。这个设置接受
以下参数：

`request`::

    (默认值) 每次请求后都执行 `fsync` 和 commit。 在硬件故障时，所有成功执行的写入操作都会
    被提交到磁盘上。

`async`::

    每隔 `sync_interval` 这么长时间执行一次 `fsync` 和 commit。 在硬件故障时，上次提交过后
    新的写入操作将会丢失。

--

`index.translog.fs.type`::
+
--

是否将事务日志的写入操作缓存在内存中。这个设置接受如下参数：

`buffered`::

    (默认值) 事务日志首先写入一个64kb的内存缓冲区，当缓冲区满或者 `fsync` 被触发或者
     `sync_interval` 间隔时间到了时才会执行持久化操作。

`simple`::

    事务日志不经过缓冲区直接写入到文件系统中。但是，这个持久化操作只会在 `fsync` 和commit
    被写入操作或者 `sync_interval` 触发时才发生。

--
